{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links to shared data MovieLens\n",
    "# source on kaggle: https://www.kaggle.com/code/quangnhatbui/movie-recommender/data\n",
    "RATINGS_SMALL_URL = 'https://drive.google.com/file/d/1BlZfCLLs5A13tbNSJZ1GPkHLWQOnPlE4/view?usp=share_link'\n",
    "MOVIES_METADATA_URL = 'https://drive.google.com/file/d/19g6-apYbZb5D-wRj4L7aYKhxS-fDM4Fb/view?usp=share_link'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightfm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f7060fd6d2ef>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mislice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproduct\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlightfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightfm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLightFM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightfm'"
     ]
    }
   ],
   "source": [
    "# just to make it available to download w/o SSL verification\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import islice, cycle, product\n",
    "\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 1. Helper functions to avoid copy paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_from_gdrive(url):\n",
    "    \"\"\"\n",
    "    gets csv data from a given url (taken from file -> share -> copy link)\n",
    "    :url: example https://drive.google.com/file/d/1BlZfCLLs5A13tbNSJZ1GPkHLWQOnPlE4/view?usp=share_link\n",
    "    \"\"\"\n",
    "    file_id = url.split('/')[-2]\n",
    "    file_path = 'https://drive.google.com/uc?export=download&id=' + file_id\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`interactions` dataset shows list of movies that users watched, along with given ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactions data\n",
    "interactions = read_csv_from_gdrive(RATINGS_SMALL_URL)\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`movies_metadata` dataset shows the list of movies existing on OKKO platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information about films etc\n",
    "movies_metadata = read_csv_from_gdrive(MOVIES_METADATA_URL)\n",
    "movies_metadata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_metadata['id'] = movies_metadata['id'].astype(str)\n",
    "interactions['movieId'] = interactions['movieId'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave only those films that intersect with each other\n",
    "interactions_filtered = interactions.loc[interactions['movieId'].isin(movies_metadata['id'])]\n",
    "print(interactions.shape, interactions_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Data preparation using LightFM Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this class we need the in the following format:\n",
    "- userId\n",
    "- movieId\n",
    "- user_features - user feature names\n",
    "- item_features - item feature names\n",
    "\n",
    "It has several methods:\n",
    "- build_interactions - definition of user / item interactions matrix using iterators on top of tuples:\n",
    "1. (userId, movieId);\n",
    "2. (userId, movieId, weight / rating)\n",
    "- build_user_features/build_item_features - defition of user/item features using iterators on top of tuples:\n",
    "1. (userId, [user_feature_name1, user_feature_name2, ...]);\n",
    "2. (userId, {user_feature_name1: weight});\n",
    "3. The same goes for item features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init class\n",
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit tuple of user and movie interactions\n",
    "dataset.fit(interactions['userId'].unique(), interactions['movieId'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have users data in MovieLens dataset so let's skip part features generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we define lightfm mapper to use it later for checks\n",
    "lightfm_mapping = dataset.mapping()\n",
    "lightfm_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightfm_mapping = {\n",
    "    'users_mapping': lightfm_mapping[0],\n",
    "    'user_features_mapping': lightfm_mapping[1],\n",
    "    'items_mapping': lightfm_mapping[2],\n",
    "    'item_features_mapping': lightfm_mapping[3],\n",
    "}\n",
    "print('user mapper length - ', len(lightfm_mapping['users_mapping']))\n",
    "print('user features mapper length - ', len(lightfm_mapping['user_features_mapping']))\n",
    "print('movies mapper length - ', len(lightfm_mapping['items_mapping']))\n",
    "print('Users movie features mapper length - ', len(lightfm_mapping['item_features_mapping']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we do not have user / movie features their length are the same as userId and movieId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create inverted mappers to check recommendations later\n",
    "lightfm_mapping['users_inv_mapping'] = {v: k for k, v in lightfm_mapping['users_mapping'].items()}\n",
    "lightfm_mapping['items_inv_mapping'] = {v: k for k, v in lightfm_mapping['items_mapping'].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned earlier, we need to create iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tuple_iterator(df: pd.DataFrame):\n",
    "    '''\n",
    "    :df: pd.DataFrame, interactions dataframe\n",
    "    returs iterator\n",
    "    '''\n",
    "    return zip(*df.values.T)\n",
    "\n",
    "def concat_last_to_list(t):\n",
    "    return (t[0], list(t[1:])[0])\n",
    "\n",
    "def df_to_tuple_list_iterator(df):\n",
    "    return map(concat_last_to_list, zip(*df.values.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train set on the whole interactions dataset (as HW you will have to split into test and train for evaluation)\n",
    "train_mat, train_mat_weights = dataset.build_interactions(df_to_tuple_iterator(interactions_filtered[['userId', 'movieId']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set params\n",
    "NO_COMPONENTS = 64\n",
    "LEARNING_RATE = .03\n",
    "LOSS = 'warp'\n",
    "MAX_SAMPLED = 5\n",
    "RANDOM_STATE = 42\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "lfm_model = LightFM(\n",
    "    no_components = NO_COMPONENTS,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    loss = LOSS,\n",
    "    max_sampled = MAX_SAMPLED,\n",
    "    random_state = RANDOM_STATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute training\n",
    "for _ in tqdm_notebook(range(EPOCHS), total = EPOCHS):\n",
    "    lfm_model.fit_partial(\n",
    "        train_mat, \n",
    "        num_threads = 4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make sense-check\n",
    "top_N = 10\n",
    "user_id = interactions['userId'][0]\n",
    "row_id = lightfm_mapping['users_mapping'][user_id]\n",
    "print(f'Rekko for user {user_id}, row number in matrix - {row_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = list(lightfm_mapping['items_mapping'].values())\n",
    "len(all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lfm_model.predict(\n",
    "    row_id,\n",
    "    all_cols,\n",
    "    num_threads = 4)\n",
    "pred, pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cols = np.argpartition(pred, -np.arange(top_N))[-top_N:][::-1]\n",
    "top_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[top_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate mapper for movieId and title names\n",
    "item_name_mapper = dict(zip(movies_metadata['id'], movies_metadata['original_title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = pd.DataFrame({'col_id': top_cols})\n",
    "recs['movieId'] = recs['col_id'].map(lightfm_mapping['items_inv_mapping'].get).astype(str)\n",
    "recs['title'] = recs['movieId'].map(item_name_mapper)\n",
    "recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- Make train/test split -- train the model appropiately and predict on test set;\n",
    "- Wrap up in function recommendations - lfm_recommend();\n",
    "- Calculate `NDCG@10` on test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2d007ce7c74fe41dcd6cb53c80a05eb04c24d9c4918ecd21236b3a1c808c520"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
